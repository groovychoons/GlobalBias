{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/2_embeddings_raw_data.csv'\n",
    "df = pd.read_csv(filename, on_bad_lines='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embedding'] = df['Embedding'].apply(ast.literal_eval)\n",
    "df['Embedding'] = df['Embedding'].apply(lambda x: [float(num) for num in x])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df['Embedding'].tolist())\n",
    "\n",
    "X_normalized = X / np.linalg.norm(X, axis=1, keepdims=True)\n",
    "\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Apply K-means clustering\n",
    "df_copy = df.copy()\n",
    "kmeans = MiniBatchKMeans(n_clusters=120, random_state=0, batch_size=2048)\n",
    "kmeans.fit(X_normalized)\n",
    "\n",
    "y_kmeans = kmeans.predict(X_normalized)\n",
    "print(y_kmeans[0:10])\n",
    "print(len(y_kmeans))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'Cluster' column to the copied DataFrame\n",
    "df_copy['Cluster'] = y_kmeans\n",
    "\n",
    "# Sort DataFrame by 'Cluster' column\n",
    "df_sorted = df_copy[['firstname', 'Cluster', 'Highest_probF_ethnicity', 'Highest_probF_value', 'Genni']].sort_values(by='Cluster')\n",
    "# Rename columns\n",
    "df_sorted.rename(columns={'Highest_probF_ethnicity': 'Ethnicity', 'Highest_probF_value': 'Ethnicity Probability', 'Genni': 'Gender'}, inplace=True)\n",
    "df_sorted['Group'] = list(zip(df_sorted['Ethnicity'], df_sorted['Gender']))\n",
    "\n",
    "# Save to csv\n",
    "csv_filename = '../data/3_clusters_120.csv'\n",
    "df_sorted.to_csv(csv_filename, index=False)\n",
    "print(f\"Sorted embeddings saved to {csv_filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing random sampling without using clustering\n",
    "# sampled_df = df_sorted.groupby(['Ethnicity', 'Gender']).apply(lambda x: x.sample(n=10, replace=True if len(x) < 10 else False)).reset_index(drop=True)\n",
    "# sampled_df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creates a df with information about each cluster\n",
    "\n",
    "cluster_sizes = df_sorted['Cluster'].value_counts().reset_index().rename(columns={'index': 'Cluster', 'Cluster': 'Size'})\n",
    "\n",
    "# Find the group with the highest count for each cluster\n",
    "highest_group = df_sorted.groupby('Cluster')['Group'].apply(lambda x: x.value_counts().idxmax()).reset_index(name='Group')\n",
    "\n",
    "# Calculate the percentage of rows with the highest group for each cluster\n",
    "highest_group_percent = df_sorted.groupby('Cluster')['Group'].apply(lambda x: (x.value_counts(normalize=True).max() * 100).round(2)).reset_index(name='Group_Acc')\n",
    "\n",
    "# Merge the dfs\n",
    "result_df = pd.merge(cluster_sizes, highest_group, on='Cluster')\n",
    "result_df = pd.merge(result_df, highest_group_percent, on='Cluster')\n",
    "\n",
    "result_df = result_df.sort_values(by='Group_Acc').reset_index(drop=True)\n",
    "\n",
    "# Remove issue clusters\n",
    "result_df = result_df[result_df['Cluster'] != 72]\n",
    "\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only takes clusters with high ethnicity/gender agreement\n",
    "\n",
    "# Filter clusters with Ethnicity and Gender Acc > 50%\n",
    "chosen_clusters = result_df[(result_df['Group_Acc'] > 50)]\n",
    "\n",
    "# Only keep size of 10 or above\n",
    "chosen_clusters = chosen_clusters[chosen_clusters['Size'] > 9]\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "print(chosen_clusters.reset_index(drop=True).tail())\n",
    "print(\"Average Cluster Size: \" + str(chosen_clusters['Size'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = chosen_clusters.groupby(['Group'])\n",
    "selected_rows_df = pd.DataFrame()\n",
    "\n",
    "for group_id, (group_label, group_data) in enumerate(grouped_df):\n",
    "    cluster_list = group_data['Cluster'].to_list()\n",
    "\n",
    "    # Find all matching rows in 'results_df' with the same 'Group'\n",
    "    # from a list of clusters\n",
    "    matching_rows = df_sorted[\n",
    "        (df_sorted['Group'] == group_label) &\n",
    "        (df_sorted['Cluster'].isin(cluster_list))\n",
    "    ]\n",
    "\n",
    "    # Take a random 10 rows from the matching rows\n",
    "    selected_rows = matching_rows.sample(n=10, random_state=32)\n",
    "\n",
    "    # Concatenate the selected rows with the 'selected_rows_df' DataFrame\n",
    "    selected_rows_df = pd.concat([selected_rows_df, selected_rows], ignore_index=True)\n",
    "\n",
    "\n",
    "selected_rows_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find any missing groups\n",
    "missing_groups = []\n",
    "\n",
    "unique_groups = list(chosen_clusters['Group'].unique())\n",
    "\n",
    "ethnicity_gender_dict = {}\n",
    "\n",
    "for ethnicity, gender in unique_groups:\n",
    "    if ethnicity not in ethnicity_gender_dict:\n",
    "        ethnicity_gender_dict[ethnicity] = set()\n",
    "    ethnicity_gender_dict[ethnicity].add(gender)\n",
    "\n",
    "missing_groups = []\n",
    "\n",
    "for ethnicity, genders in ethnicity_gender_dict.items():\n",
    "    if 'F' not in genders:\n",
    "        missing_groups.append((ethnicity, 'F'))\n",
    "    elif 'M' not in genders:\n",
    "        missing_groups.append((ethnicity, 'M'))\n",
    "\n",
    "print(missing_groups)\n",
    "\n",
    "unique_groups_sorted = sorted(unique_groups + missing_groups)\n",
    "for group in unique_groups_sorted:\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print 10 random first names from each ethnicity with missing gender pair\n",
    "missing_groups.append(('ENGLISH', 'F'))\n",
    "missing_groups.append(('ENGLISH', 'M'))\n",
    "\n",
    "for group in missing_groups:\n",
    "    selected_rows = df_sorted[(df_sorted[\"Group\"] == group) & (df_sorted['Ethnicity Probability'] > 90)].sample(n=10, replace=False, random_state=4)\n",
    "    selected_rows_df = pd.concat([selected_rows_df, selected_rows], ignore_index=True)\n",
    "    print(f\"{group}: {selected_rows['firstname'].tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rows_df.to_csv('../data/3_name_groups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of different groups: \", len(selected_rows_df['Group'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
