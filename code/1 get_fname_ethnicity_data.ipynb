{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/genni-ethnea-authority2009.tsv'\n",
    "\n",
    "df = pd.read_csv(filename, delimiter='\\t', on_bad_lines='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['firstname'] = df['firstname'].str.capitalize()\n",
    "\n",
    "# Remove names with spaces or hyphens or len 1 or less\n",
    "df = df[df['firstname'].str.len() > 1]\n",
    "df = df[df['firstname'].str.len() < 14]\n",
    "df = df[~df['firstname'].str.contains(r'[\\s-]')]\n",
    "\n",
    "# Remove names without gender info\n",
    "df = df[df['Genni'] != \"-\"]\n",
    "\n",
    "# Create a new df with unique names\n",
    "unique_names_df = df.drop_duplicates(subset='firstname', keep='first', ignore_index=True)\n",
    "unique_names_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def scrape_ethnicity_table(first_name, last_name):\n",
    "    url = f\"http://abel.lis.illinois.edu/cgi-bin/ethnea/search.py?Fname={first_name}&Lname={last_name}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    # Extract the table data\n",
    "    data = [[cell.text for cell in row.find_all('td')] for row in rows[1:]]\n",
    "\n",
    "    # Find the ethnicity with the highest probF\n",
    "    max_probF_ethnicity = None\n",
    "    max_probF_value = 0.0\n",
    "    for row in data:\n",
    "        ethnicity = row[0]\n",
    "        probF = float(row[4])\n",
    "        if probF > max_probF_value:\n",
    "            max_probF_ethnicity = ethnicity\n",
    "            max_probF_value = probF\n",
    "\n",
    "    # Update the DataFrame with the highest probF ethnicity and probF value\n",
    "    unique_names_df.loc[(unique_names_df['firstname'] == first_name) & (unique_names_df['lastname'] == last_name), 'Highest_probF_ethnicity'] = max_probF_ethnicity\n",
    "    unique_names_df.loc[(unique_names_df['firstname'] == first_name) & (unique_names_df['lastname'] == last_name), 'Highest_probF_value'] = max_probF_value\n",
    "\n",
    "chunk_size = 1000\n",
    "\n",
    "for i in range(0, len(unique_names_df), chunk_size):\n",
    "    chunk_df = unique_names_df.iloc[i:i+chunk_size]\n",
    "\n",
    "    for index, row in chunk_df.iterrows():\n",
    "        first_name = row['firstname']\n",
    "        last_name = row['lastname']\n",
    "        scrape_ethnicity_table(first_name, last_name)\n",
    "        time.sleep(1)  # Delay for 1 second before the next request\n",
    "    \n",
    "    filename = f\"../data/1_first_names_{i//chunk_size}.csv\"\n",
    "\n",
    "    unique_names_df.iloc[i:i+chunk_size].to_csv(filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = '../data/'\n",
    "\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.startswith('1_first_names_') and file.endswith('.csv')]\n",
    "csv_files.sort()  # Sort the file list alphabetically\n",
    "\n",
    "df_list = []\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_list.append(df)\n",
    "\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "merged_df.drop_duplicates(inplace=True)\n",
    "\n",
    "merged_csv_path = '../data/1_first_names_raw_data.csv'\n",
    "merged_df.to_csv(merged_csv_path, index=False)\n",
    "\n",
    "print(\"Merged CSV file has been created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
